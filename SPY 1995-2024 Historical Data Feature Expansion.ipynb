{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SPY 1995-2024 Historical Data Feature Expansion\n",
        "\n",
        "This script performs leakage-safe feature engineering on historical SPY daily OHLCV data to prepare it for supervised machine learning. It constructs a set of simple but informative predictors using only information available at the end of each trading day, including daily returns, lagged returns, rolling volatility, moving averages, momentum measures, volume dynamics, and calendar effects. The script also defines the prediction target as the direction of the next dayâ€™s price movement, ensuring that no future information is used in the input features. The resulting dataset is chronologically ordered and suitable for time-series classification experiments evaluating next-day market direction."
      ],
      "metadata": {
        "id": "UYUB6etX-Mh-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVhqhsJ--L8o",
        "outputId": "4b9ed459-dba4-40e5-8ac9-d94b94af72ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved leak-free dataset to: SPY_1995_2024_features_leakfree_v2.csv\n",
            "Rows: 7,751  Columns: 45\n",
            "Label distribution (y_next_dir):\n",
            "y_next_dir\n",
            "-1.0    3539\n",
            " 0.0      37\n",
            " 1.0    4175\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Leakage-safe feature engineering for SPY OHLCV time series.\n",
        "\n",
        "Creates:\n",
        "- Daily return ret_1d (Close_t / Close_{t-1} - 1)\n",
        "- Lagged returns ret_1d_lag1..ret_1d_lagK\n",
        "- Rolling volatility of returns (std) over multiple windows\n",
        "- Moving averages of Close and price-to-MA ratios (trend/level)\n",
        "- Momentum features (k-day return using Close_t and Close_{t-k})\n",
        "- Volume changes (pct change), rolling volume means, volume z-score vs rolling window\n",
        "- Calendar effects: day-of-week, month, day-of-month, week-of-year (optional)\n",
        "- Label y_next_dir = sign(Close_{t+1} - Close_t)\n",
        "\n",
        "Input:  SPY_1995_2024_raw_data.csv\n",
        "Output: SPY_1995_2024_features_leakfree_v2.csv\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "INPUT_CSV = \"SPY_1995_2024_raw_data.csv\"\n",
        "OUTPUT_CSV = \"SPY_1995_2024_features_leakfree_v2.csv\"\n",
        "\n",
        "\n",
        "# ---- Feature config (keep simple but informative) ----\n",
        "LAG_K = 10                        # lagged daily returns up to t-k\n",
        "RET_VOL_WINDOWS = (5, 10, 20)     # rolling vol windows on returns\n",
        "MA_WINDOWS = (5, 10, 20, 50)      # moving averages on Close\n",
        "MOM_WINDOWS = (5, 10, 20)         # momentum windows (k-day return)\n",
        "VOL_ROLL_WINDOWS = (5, 20)        # rolling mean/std windows on Volume\n",
        "\n",
        "\n",
        "def _pick_close_column(df: pd.DataFrame) -> str:\n",
        "    candidates = [\"Close\", \"close\", \"Adj Close\", \"Adj_Close\", \"adj close\", \"adj_close\"]\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    raise ValueError(\n",
        "        f\"Could not find a close column. Expected one of: {candidates}. \"\n",
        "        f\"Found columns: {list(df.columns)}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _pick_date_column(df: pd.DataFrame) -> str:\n",
        "    candidates = [\"Date\", \"date\", \"timestamp\", \"Datetime\", \"datetime\", \"Time\", \"time\"]\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    raise ValueError(\n",
        "        f\"Could not find a date column. Expected one of: {candidates}. \"\n",
        "        f\"Found columns: {list(df.columns)}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    df = pd.read_csv(INPUT_CSV)\n",
        "\n",
        "    # Parse date + sort chronologically\n",
        "    date_col = _pick_date_column(df)\n",
        "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[date_col]).sort_values(date_col).reset_index(drop=True)\n",
        "\n",
        "    close_col = _pick_close_column(df)\n",
        "\n",
        "    # Coerce core numeric columns (best-effort)\n",
        "    for col in [\"Open\", \"High\", \"Low\", close_col, \"Volume\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 1) Calendar features (all known from Date at time t; leak-free)\n",
        "    # ------------------------------------------------------------------\n",
        "    df[\"dow\"] = df[date_col].dt.dayofweek          # 0=Mon ... 6=Sun (trading days are 0-4)\n",
        "    df[\"month\"] = df[date_col].dt.month            # 1..12\n",
        "    df[\"dom\"] = df[date_col].dt.day                # day of month 1..31\n",
        "    # ISO week can be helpful; keep as int\n",
        "    df[\"weekofyear\"] = df[date_col].dt.isocalendar().week.astype(int)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 2) Returns and lagged returns (leak-free: uses <= t)\n",
        "    # ------------------------------------------------------------------\n",
        "    df[\"ret_1d\"] = df[close_col].pct_change()  # (Close_t / Close_{t-1}) - 1\n",
        "\n",
        "    # Lagged returns ret_1d_lag1..ret_1d_lagK\n",
        "    for k in range(1, LAG_K + 1):\n",
        "        df[f\"ret_1d_lag{k}\"] = df[\"ret_1d\"].shift(k)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 3) Rolling volatility of returns (std) (leak-free: window ends at t)\n",
        "    # ------------------------------------------------------------------\n",
        "    for w in RET_VOL_WINDOWS:\n",
        "        df[f\"ret_vol_{w}d\"] = df[\"ret_1d\"].rolling(window=w, min_periods=w).std()\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 4) Moving averages of price + price-to-MA ratios (trend/level)\n",
        "    #    (leak-free: uses Close up to t)\n",
        "    # ------------------------------------------------------------------\n",
        "    for w in MA_WINDOWS:\n",
        "        ma = df[close_col].rolling(window=w, min_periods=w).mean()\n",
        "        df[f\"ma_close_{w}d\"] = ma\n",
        "        # Ratio and distance to MA (both common, simple signals)\n",
        "        df[f\"close_over_ma_{w}d\"] = df[close_col] / ma\n",
        "        df[f\"close_minus_ma_{w}d\"] = df[close_col] - ma\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 5) Momentum features: k-day return Close_t vs Close_{t-k}\n",
        "    #    (leak-free by definition)\n",
        "    # ------------------------------------------------------------------\n",
        "    for k in MOM_WINDOWS:\n",
        "        df[f\"mom_{k}d\"] = df[close_col] / df[close_col].shift(k) - 1.0\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 6) Volume dynamics (leak-free: uses Volume up to t)\n",
        "    # ------------------------------------------------------------------\n",
        "    if \"Volume\" in df.columns:\n",
        "        df[\"vol_chg_1d\"] = df[\"Volume\"].pct_change()\n",
        "\n",
        "        for w in VOL_ROLL_WINDOWS:\n",
        "            vmean = df[\"Volume\"].rolling(window=w, min_periods=w).mean()\n",
        "            vstd = df[\"Volume\"].rolling(window=w, min_periods=w).std()\n",
        "            df[f\"vol_mean_{w}d\"] = vmean\n",
        "            df[f\"vol_z_{w}d\"] = (df[\"Volume\"] - vmean) / vstd\n",
        "    else:\n",
        "        # Keep columns consistent if Volume not present\n",
        "        df[\"vol_chg_1d\"] = np.nan\n",
        "        for w in VOL_ROLL_WINDOWS:\n",
        "            df[f\"vol_mean_{w}d\"] = np.nan\n",
        "            df[f\"vol_z_{w}d\"] = np.nan\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 7) Label: next-day direction (allowed to use t+1 ONLY for y)\n",
        "    # ------------------------------------------------------------------\n",
        "    next_close = df[close_col].shift(-1)\n",
        "    df[\"y_next_dir\"] = np.sign(next_close - df[close_col]).astype(\"float\")  # -1, 0, +1\n",
        "\n",
        "    # Optional binary version (uncomment if needed):\n",
        "    # df[\"y_next_up\"] = ((next_close - df[close_col]) > 0).astype(int)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 8) Build final output, dropping unusable rows (NaNs from lag/rolling + last label)\n",
        "    # ------------------------------------------------------------------\n",
        "    raw_cols = [c for c in [date_col, \"Open\", \"High\", \"Low\", close_col, \"Volume\"] if c in df.columns]\n",
        "\n",
        "    engineered_cols = []\n",
        "    engineered_cols += [\"dow\", \"month\", \"dom\", \"weekofyear\"]\n",
        "    engineered_cols += [\"ret_1d\"] + [f\"ret_1d_lag{k}\" for k in range(1, LAG_K + 1)]\n",
        "    engineered_cols += [f\"ret_vol_{w}d\" for w in RET_VOL_WINDOWS]\n",
        "    engineered_cols += [f\"ma_close_{w}d\" for w in MA_WINDOWS]\n",
        "    engineered_cols += [f\"close_over_ma_{w}d\" for w in MA_WINDOWS]\n",
        "    engineered_cols += [f\"close_minus_ma_{w}d\" for w in MA_WINDOWS]\n",
        "    engineered_cols += [f\"mom_{k}d\" for k in MOM_WINDOWS]\n",
        "    engineered_cols += [\"vol_chg_1d\"] + [f\"vol_mean_{w}d\" for w in VOL_ROLL_WINDOWS] + [f\"vol_z_{w}d\" for w in VOL_ROLL_WINDOWS]\n",
        "\n",
        "    label_col = \"y_next_dir\"\n",
        "\n",
        "    out_cols = raw_cols + engineered_cols + [label_col]\n",
        "    out = df[out_cols].copy()\n",
        "\n",
        "    # Require label + core return and at least the maximum lag/rolling windows.\n",
        "    # This ensures no NaNs in your chosen feature set.\n",
        "    required = [\"ret_1d\", f\"ret_1d_lag{LAG_K}\", f\"ret_vol_{max(RET_VOL_WINDOWS)}d\", f\"ma_close_{max(MA_WINDOWS)}d\", f\"mom_{max(MOM_WINDOWS)}d\", label_col]\n",
        "    # Also require volume features only if Volume exists\n",
        "    if \"Volume\" in df.columns:\n",
        "        required += [f\"vol_mean_{max(VOL_ROLL_WINDOWS)}d\", f\"vol_z_{max(VOL_ROLL_WINDOWS)}d\"]\n",
        "\n",
        "    out = out.dropna(subset=required)\n",
        "\n",
        "    out.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"Saved leak-free dataset to: {OUTPUT_CSV}\")\n",
        "    print(f\"Rows: {len(out):,}  Columns: {len(out.columns)}\")\n",
        "    print(\"Label distribution (y_next_dir):\")\n",
        "    print(out[label_col].value_counts(dropna=False).sort_index())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}