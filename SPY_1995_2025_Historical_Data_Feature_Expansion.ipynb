{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SPY 1995-2025 Historical Data Feature Expansion\n",
        "\n",
        "This script performs leakage-safe feature engineering on historical SPY daily OHLCV data to prepare it for supervised machine learning. It constructs a set of simple but informative predictors using only information available at the end of each trading day, including daily returns, lagged returns, rolling volatility, moving averages, momentum measures, volume dynamics, and calendar effects. The script also defines the prediction target as the direction of the next dayâ€™s price movement, ensuring that no future information is used in the input features. The resulting dataset is chronologically ordered and suitable for time-series classification experiments evaluating next-day market direction."
      ],
      "metadata": {
        "id": "UYUB6etX-Mh-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVhqhsJ--L8o",
        "outputId": "4b9ed459-dba4-40e5-8ac9-d94b94af72ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved leak-free dataset to: SPY_1995_2024_features_leakfree_v2.csv\n",
            "Rows: 7,751  Columns: 45\n",
            "Label distribution (y_next_dir):\n",
            "y_next_dir\n",
            "-1.0    3539\n",
            " 0.0      37\n",
            " 1.0    4175\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Input:  SPY_1995_2025_raw_data.csv\n",
        "Output: SPY_1995_2025_feature_expansion.csv\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "INPUT_CSV = \"SPY_1995_2025_raw_data.csv\"\n",
        "OUTPUT_CSV = \"SPY_1995_2025_feature_expansion.csv\"\n",
        "\n",
        "\n",
        "LAG_K = 10 # lagged daily returns up to t-k\n",
        "RET_VOL_WINDOWS = (5, 10, 20) # rolling vol windows on returns\n",
        "MA_WINDOWS = (5, 10, 20, 50) # moving averages on Close\n",
        "MOM_WINDOWS = (5, 10, 20) # momentum windows (k-day return)\n",
        "VOL_ROLL_WINDOWS = (5, 20) # rolling mean/std windows on Volume\n",
        "\n",
        "\n",
        "def _pick_close_column(df: pd.DataFrame) -> str:\n",
        "    candidates = [\"Close\", \"close\", \"Adj Close\", \"Adj_Close\", \"adj close\", \"adj_close\"]\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    raise ValueError(\n",
        "        f\"Could not find a close column. Expected one of: {candidates}. \"\n",
        "        f\"Found columns: {list(df.columns)}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _pick_date_column(df: pd.DataFrame) -> str:\n",
        "    candidates = [\"Date\", \"date\", \"timestamp\", \"Datetime\", \"datetime\", \"Time\", \"time\"]\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    raise ValueError(\n",
        "        f\"Could not find a date column. Expected one of: {candidates}. \"\n",
        "        f\"Found columns: {list(df.columns)}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    df = pd.read_csv(INPUT_CSV)\n",
        "\n",
        "    # Parse date + sort chronologically\n",
        "    date_col = _pick_date_column(df)\n",
        "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[date_col]).sort_values(date_col).reset_index(drop=True)\n",
        "\n",
        "    close_col = _pick_close_column(df)\n",
        "\n",
        "    # Coerce core numeric columns (best-effort)\n",
        "    for col in [\"Open\", \"High\", \"Low\", close_col, \"Volume\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    # 1) Calendar features (all known from Date at time t; leak-free)\n",
        "    df[\"dow\"] = df[date_col].dt.dayofweek\n",
        "    df[\"month\"] = df[date_col].dt.month\n",
        "    df[\"dom\"] = df[date_col].dt.day\n",
        "    df[\"weekofyear\"] = df[date_col].dt.isocalendar().week.astype(int)\n",
        "\n",
        "\n",
        "    # 2) Returns and lagged returns (leak-free: uses <= t)\n",
        "    df[\"ret_1d\"] = df[close_col].pct_change()\n",
        "\n",
        "    # Lagged returns ret_1d_lag1..ret_1d_lagK\n",
        "    for k in range(1, LAG_K + 1):\n",
        "        df[f\"ret_1d_lag{k}\"] = df[\"ret_1d\"].shift(k)\n",
        "\n",
        "\n",
        "    # 3) Rolling volatility of returns (std) (leak-free: window ends at t)\n",
        "    for w in RET_VOL_WINDOWS:\n",
        "        df[f\"ret_vol_{w}d\"] = df[\"ret_1d\"].rolling(window=w, min_periods=w).std()\n",
        "\n",
        "\n",
        "    # 4) Moving averages of price + price-to-MA ratios (trend/level)\n",
        "    for w in MA_WINDOWS:\n",
        "        ma = df[close_col].rolling(window=w, min_periods=w).mean()\n",
        "        df[f\"ma_close_{w}d\"] = ma\n",
        "        # Ratio and distance to MA (both common, simple signals)\n",
        "        df[f\"close_over_ma_{w}d\"] = df[close_col] / ma\n",
        "        df[f\"close_minus_ma_{w}d\"] = df[close_col] - ma\n",
        "\n",
        "\n",
        "    # 5) Momentum features: k-day return Close_t vs Close_{t-k}\n",
        "    for k in MOM_WINDOWS:\n",
        "        df[f\"mom_{k}d\"] = df[close_col] / df[close_col].shift(k) - 1.0\n",
        "\n",
        "\n",
        "    # 6) Volume dynamics (leak-free: uses Volume up to t)\n",
        "    if \"Volume\" in df.columns:\n",
        "        df[\"vol_chg_1d\"] = df[\"Volume\"].pct_change()\n",
        "\n",
        "        for w in VOL_ROLL_WINDOWS:\n",
        "            vmean = df[\"Volume\"].rolling(window=w, min_periods=w).mean()\n",
        "            vstd = df[\"Volume\"].rolling(window=w, min_periods=w).std()\n",
        "            df[f\"vol_mean_{w}d\"] = vmean\n",
        "            df[f\"vol_z_{w}d\"] = (df[\"Volume\"] - vmean) / vstd\n",
        "    else:\n",
        "        # Keep columns consistent if Volume not present\n",
        "        df[\"vol_chg_1d\"] = np.nan\n",
        "        for w in VOL_ROLL_WINDOWS:\n",
        "            df[f\"vol_mean_{w}d\"] = np.nan\n",
        "            df[f\"vol_z_{w}d\"] = np.nan\n",
        "\n",
        "\n",
        "    # 7) Label: next-day direction (allowed to use t+1 ONLY for y)\n",
        "    next_close = df[close_col].shift(-1)\n",
        "    df[\"y_next_dir\"] = np.sign(next_close - df[close_col]).astype(\"float\")\n",
        "\n",
        "    # Optional binary version (uncomment if needed):\n",
        "    # df[\"y_next_up\"] = ((next_close - df[close_col]) > 0).astype(int)\n",
        "\n",
        "\n",
        "    # 8) Build final output, dropping unusable rows (NaNs from lag/rolling + last label)\n",
        "    raw_cols = [c for c in [date_col, \"Open\", \"High\", \"Low\", close_col, \"Volume\"] if c in df.columns]\n",
        "\n",
        "    engineered_cols = []\n",
        "    engineered_cols += [\"dow\", \"month\", \"dom\", \"weekofyear\"]\n",
        "    engineered_cols += [\"ret_1d\"] + [f\"ret_1d_lag{k}\" for k in range(1, LAG_K + 1)]\n",
        "    engineered_cols += [f\"ret_vol_{w}d\" for w in RET_VOL_WINDOWS]\n",
        "    engineered_cols += [f\"ma_close_{w}d\" for w in MA_WINDOWS]\n",
        "    engineered_cols += [f\"close_over_ma_{w}d\" for w in MA_WINDOWS]\n",
        "    engineered_cols += [f\"close_minus_ma_{w}d\" for w in MA_WINDOWS]\n",
        "    engineered_cols += [f\"mom_{k}d\" for k in MOM_WINDOWS]\n",
        "    engineered_cols += [\"vol_chg_1d\"] + [f\"vol_mean_{w}d\" for w in VOL_ROLL_WINDOWS] + [f\"vol_z_{w}d\" for w in VOL_ROLL_WINDOWS]\n",
        "\n",
        "    label_col = \"y_next_dir\"\n",
        "\n",
        "    out_cols = raw_cols + engineered_cols + [label_col]\n",
        "    out = df[out_cols].copy()\n",
        "\n",
        "    # Require label + core return and at least the maximum lag/rolling windows.\n",
        "    required = [\"ret_1d\", f\"ret_1d_lag{LAG_K}\", f\"ret_vol_{max(RET_VOL_WINDOWS)}d\", f\"ma_close_{max(MA_WINDOWS)}d\", f\"mom_{max(MOM_WINDOWS)}d\", label_col]\n",
        "    # Also require volume features only if Volume exists\n",
        "    if \"Volume\" in df.columns:\n",
        "        required += [f\"vol_mean_{max(VOL_ROLL_WINDOWS)}d\", f\"vol_z_{max(VOL_ROLL_WINDOWS)}d\"]\n",
        "\n",
        "    out = out.dropna(subset=required)\n",
        "\n",
        "    out.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"Saved leak-free dataset to: {OUTPUT_CSV}\")\n",
        "    print(f\"Rows: {len(out):,}  Columns: {len(out.columns)}\")\n",
        "    print(\"Label distribution (y_next_dir):\")\n",
        "    print(out[label_col].value_counts(dropna=False).sort_index())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}